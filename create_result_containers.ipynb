{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphing water vapor from SAPHIR\n",
    "### Erfan Jahangir and Brian Mapes March 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General strategy of this notebook\n",
    "\n",
    "Like any programming job, we work backward from a result-shaped container, and forward from the most precious original data input whose value we are trying to optimize. These intentions make it natural to build the middle steps and grab auxiliary inputs, as necessary to achieve success. Initially we achieve success in the simplest way, then later add sophistication -- but only to the extent it improves signal and reduces noise, as seen in the initial success of the data products. \n",
    "\n",
    "In this case, the results-shaped container is a single 1/2-degree (for now) array of \n",
    "\n",
    "1. **WV** (water vapor)\n",
    "1. **AT** (the 'analysis tendency' of the morphing operation, representing all the physical source-sink terms). \n",
    "1. **t_early** (the time of the earlier observation that made the above products)\n",
    "1. **t_late** (the time of the later observation \" \" \" )\n",
    "\n",
    "In this case, the precious data is swaths of data, made up of pixels, of WV500 retrieved from SAPHIR channels by Helene Brignietz and colleagues. These input data include arrays of: \n",
    "\n",
    "* the WV **value** at each pixel\n",
    "* the **latitude** \" \" \" \n",
    "* the **longitude** \" \" \" \n",
    "* the **time of observation** \" \" \" \n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-9b15da9d7b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2012_07_01_1.mat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/MPO624/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/MPO624/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File('2012_07_01_1.mat','r')\n",
    "variables = f.items()\n",
    "\n",
    "for var in variables:\n",
    "    name = var[0]\n",
    "    data = var[1]\n",
    "    print(\"Name \", name)  # Name\n",
    "    if type(data) is h5py.Dataset:\n",
    "        # If DataSet pull the associated Data\n",
    "        # If not a dataset, you may need to access the element sub-items\n",
    "        value = data.value\n",
    "        print(\"Value\", value)  # NumPy Array / Value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'loadmat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5fea59538a51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2012_07_01_1.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'loadmat'"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('')\n",
    "mat.loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mat.get('swarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create the results-shaped containers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DX = 0.5 # degrees\n",
    "SOUTH = -30 # Central latitudes of southern grid  cells\n",
    "NORTH = 30  # \" \" northern \" \" \n",
    "WEST = 0.25 # Central longitude of westernmost cell\n",
    "EAST = 359.75 # \" \" easternmost \" \n",
    "\n",
    "# Build 1D spatial coordinate arrays \n",
    "NLAT = int( (NORTH-SOUTH)/DX )\n",
    "lat = np.linspace(SOUTH, NORTH, NLAT)\n",
    "\n",
    "NLON = int( (EAST-WEST)/DX )\n",
    "lon = np.linspace(WEST, EAST, NLON)\n",
    "\n",
    "\n",
    "# Now build containers for the results we desire\n",
    "# Which order? LON,LAT? or LAT,LON? \n",
    "\n",
    "WV = np.zeros( (NLON,NLAT) )\n",
    "AT = np.zeros( (NLON,NLAT) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable   Type       Data/Info\n",
      "-------------------------------\n",
      "AT         ndarray    719x120: 86280 elems, type `float64`, 690240 bytes (674.0625 kb)\n",
      "DX         float      0.5\n",
      "EAST       float      359.75\n",
      "NLAT       int        120\n",
      "NLON       int        719\n",
      "NORTH      int        30\n",
      "SOUTH      int        -30\n",
      "WEST       float      0.25\n",
      "WV         ndarray    719x120: 86280 elems, type `float64`, 690240 bytes (674.0625 kb)\n",
      "lat        ndarray    120: 120 elems, type `float64`, 960 bytes\n",
      "lon        ndarray    719: 719 elems, type `float64`, 5752 bytes\n",
      "np         module     <module 'numpy' from '//a<...>kages/numpy/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: The things we need to fill the containers\n",
    "\n",
    "To fill the above arrays, we will use the *time-proximity-weighted average* for WV500:  \n",
    "\n",
    "$ WV500 = ( WV_{before}*dt_{after} + WV_{before}*dt_{after} )/(dt_{before} + dt_{after}) $ \n",
    "\n",
    "and the simplest *estimate of the time derivative* using the before and after observations:\n",
    "\n",
    "$ AT500 = ( WV_{after} - WV_{before})/(dt_{before} + dt_{after}) $ \n",
    "\n",
    "**Thus, we need $ WV_{before}, WV_{after}, dt_{before}, dt_{after}  $**\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Containers for the necessary quantities to get our final products\n",
    "\n",
    "WV_before = np.zeros( (NLON,NLAT) )\n",
    "WV_after  = np.zeros( (NLON,NLAT) )\n",
    "dt_before = np.zeros( (NLON,NLAT) )\n",
    "dt_after  = np.zeros( (NLON,NLAT) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable    Type       Data/Info\n",
      "--------------------------------\n",
      "AT          ndarray    719x120: 86280 elems, type `float64`, 690240 bytes (674.0625 kb)\n",
      "DX          float      0.5\n",
      "EAST        float      359.75\n",
      "NLAT        int        120\n",
      "NLON        int        719\n",
      "NORTH       int        30\n",
      "SOUTH       int        -30\n",
      "WEST        float      0.25\n",
      "WV          ndarray    719x120: 86280 elems, type `float64`, 690240 bytes (674.0625 kb)\n",
      "WV_after    ndarray    719x120: 86280 elems, type `float64`, 690240 bytes (674.0625 kb)\n",
      "WV_before   ndarray    719x120: 86280 elems, type `float64`, 690240 bytes (674.0625 kb)\n",
      "dt_after    ndarray    719x120: 86280 elems, type `float64`, 690240 bytes (674.0625 kb)\n",
      "dt_before   ndarray    719x120: 86280 elems, type `float64`, 690240 bytes (674.0625 kb)\n",
      "lat         ndarray    120: 120 elems, type `float64`, 960 bytes\n",
      "lon         ndarray    719: 719 elems, type `float64`, 5752 bytes\n",
      "np          module     <module 'numpy' from '//a<...>kages/numpy/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, how to get $ WV_{before}, WV_{after}, dt_{before}, dt_{after} $ ? \n",
    "\n",
    "#### We need two _time stacks_ of product-shaped lat-lon arrays. \n",
    "\n",
    "Two, because we need the VALUE and the TIME of each observation we put into the stack. \n",
    "\n",
    "These stack is a 3D array, centered on the product time (dt=0). It doesn't matter how long in time  this stack extends, as long as it is long enough that **every pixel in space has a before and an after observation**. That is, the DTMAX just has to be at least as big as the longest time gap between observations. Also, the time step between the layers in the stack just has to be short enough that we aren't wasting observations by over-writing some locations with multiple observations. Since the orbit time is about 100 minutes, 1 hour stacks are safe. \n",
    "\n",
    "Initially, let's make a container full of zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTMAX = 6    # hours. The size of the centered stack will then be 2*DTMAX+1. \n",
    "DTstack = 1  # hour\n",
    "\n",
    "WV_stack = np.zeros( (NLON,NLAT, 2*DTMAX+1) )\n",
    "tobs_stack = np.zeros( (NLON,NLAT, 2*DTMAX+1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable     Type       Data/Info\n",
      "---------------------------------\n",
      "AT           ndarray    719x120: 86280 elems, type `float64`, 690240 bytes (674.0625 kb)\n",
      "DTMAX        int        6\n",
      "DTstack      int        1\n",
      "DX           float      0.5\n",
      "EAST         float      359.75\n",
      "NLAT         int        120\n",
      "NLON         int        719\n",
      "NORTH        int        30\n",
      "SOUTH        int        -30\n",
      "WEST         float      0.25\n",
      "WV           ndarray    719x120: 86280 elems, type `float64`, 690240 bytes (674.0625 kb)\n",
      "WV_after     ndarray    719x120: 86280 elems, type `float64`, 690240 bytes (674.0625 kb)\n",
      "WV_before    ndarray    719x120: 86280 elems, type `float64`, 690240 bytes (674.0625 kb)\n",
      "WV_stack     ndarray    719x120x13: 1121640 elems, type `float64`, 8973120 bytes (8.55743408203125 Mb)\n",
      "dt_after     ndarray    719x120: 86280 elems, type `float64`, 690240 bytes (674.0625 kb)\n",
      "dt_before    ndarray    719x120: 86280 elems, type `float64`, 690240 bytes (674.0625 kb)\n",
      "lat          ndarray    120: 120 elems, type `float64`, 960 bytes\n",
      "lon          ndarray    719: 719 elems, type `float64`, 5752 bytes\n",
      "np           module     <module 'numpy' from '//a<...>kages/numpy/__init__.py'>\n",
      "tobs_stack   ndarray    719x120x13: 1121640 elems, type `float64`, 8973120 bytes (8.55743408203125 Mb)\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now the real data work is clear.\n",
    "\n",
    "1. **How do we interrogate the stack** to get $ WV_{before}, WV_{after}, dt_{before}, dt_{after} $? \n",
    "    * For each location (lat,lon), the stack is a time series of length 2\\*DTMAX+1. \n",
    "    * Need a method to find nonzero values closest to dt=0 (the center of the series). \n",
    "    * Special case: when there is an observation in dt=0, that is WV -- but what is AT?\n",
    "1. **How do we fill the stack initially**, from the set of observation pixels within DTMAX of the time of the product? \n",
    "    * Loop over all the pixels in the input data within +/- DTMAX of the product hour. \n",
    "        * Each pixel has these values: {WVobs, tobs, latobs, lonobs}.\n",
    "    * Place the pixel in the dt=0 layer of WV_stack and tobs_stack, at location (latobs, lonobs)\n",
    "    * Place the pixel in the dt=1 layer at (latobs +v\\*DT_stack\\*1, lonobs +u\\*DT_stack\\*1)\n",
    "        * this requires obtaining wind data u,v for that location (reanalysis u500,v500)\n",
    "    * etc. for other dt layers in the stack\n",
    "1. **How do we repeat the process for the next product hour?** \n",
    "    * We could start the whole process over from np.zeros(). Inefficient but safe. \n",
    "    * Better from efficieny perspective is to \n",
    "        * np.roll(WV_stack), np.roll(tobs_stack) to recenter the stack on the next hour.\n",
    "        * WV_stack[:,:,DTMAX\\*2]=0  to clobber where the periodic roll() operation has shifted past data into the future\n",
    "        * Now just fill that future stack time, WV_stack[:,:,DTMAX\\*2], with real data\n",
    "            * this involves querying the satellite data up to DTMAX hours ahead of that time, shifting it all backward in time\n",
    "            * (latobs -v\\*DT_stack\\*DTMAX, latobs -u\\*DT_stack\\*DTMAX)\n",
    "            * (latobs -v\\*DT_stack\\*(DTMAX-1), latobs -u\\*DT_stack\\*(DTMAX-1))\n",
    "            * etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
